{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de Estatística Aplicada\n",
    "\n",
    "## Regressão Linear Múltipla\n",
    "\n",
    "### Grupo:\n",
    "\n",
    "* Rafael G. de Pontes\n",
    "* Henrique Arriel\n",
    "* Jonathan L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Os dados coletados para esta análise foram retirados do site [kaggle](https://www.kaggle.com/crisparada/brazilian-cities). Eles foram liberados por [Cristina Parada](https://www.kaggle.com/crisparada), sob a licença [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), publicados no dia 24/05/2019. Tratam-se de dados de diversas cidades do Brasil, tais como: população, número de unidades domiciliares, telefones fixos, TVs por assinatura, censos populacionais estratificados por idade, zona urbana ou rural, dentre outros. Ao todo, são 79 campos para cada cidade documentada. As descrições completas dos dados, em inglês, juntamente com suas respectivas fontes, podem ser vistas a seguir:\n",
    "\n",
    "FIELD - DESCRIPTION - REFERENCE - UNIT - SOURCE\n",
    "\n",
    "CITY - Name of the City\n",
    "\n",
    "STATE - Name of the State\n",
    "\n",
    "CAPITAL - 1 if Capital of State\n",
    "\n",
    "IBGE_RES_POP - Resident Population - 2010 - source\n",
    "\n",
    "IBGE_RES_POP_BRAS - Resident Population Brazilian - 2010 - source\n",
    "\n",
    "IBGE_RES_POP_ESTR - Redident Population Foreigners - 2010 - source\n",
    "\n",
    "IBGE_DU - Domestic Units Total - 2010 - source\n",
    "\n",
    "IBGE_DU_URBAN - Domestic Units Urban - 2010 - source\n",
    "\n",
    "IBGE_DU_RURAL - Domestic Units Rural 2010 - source\n",
    "\n",
    "IBGE_POP - Resident Population Regular Urban Planning - 2010 - source\n",
    "\n",
    "IBGE_1 - Resident Population Regular Urban Planning - until 1 y.o - 2010 - source\n",
    "\n",
    "IBGE_1-4 - Resident Population Regular Urban Planning - from 1 to 4 y.o - 2010 - source\n",
    "\n",
    "IBGE_5-9 - Resident Population Regular Urban Planning - from 4 to 9 y.o - 2010 - source\n",
    "\n",
    "IBGE_10-14 - Resident Population Regular Urban Planning - from 10 to 14 y.o - 2010 - source\n",
    "\n",
    "IBGE_15-59 - Resident Population Regular Urban Planning - from 15 to 59 y.o 2010 - source\n",
    "\n",
    "IBGE_60+ - Resident Population Regular Urban Planning - above 60 y.o - 2010 - source\n",
    "\n",
    "IBGE_PLANTED_AREA - Planted Area (hectares) - 2017 - 1 hectare (1 hectare = 10,000 square meters) - source\n",
    "\n",
    "IBGE_CROP_PRODUCTION_$ - Crop Production - 2017 - $ 1,000 reais - source\n",
    "\n",
    "IDHM Ranking - HDI Ranking - 2010 - source\n",
    "\n",
    "IDHM - HDI Human Development Index - 2010 - source\n",
    "\n",
    "IDHM_Renda - HDI GNI Index - 2010 - source\n",
    "\n",
    "IDHM_Longevidade - HDI Life Expectancy index - 2010 - source\n",
    "\n",
    "IDHM_Educacao HDI Education index - 2010 - source\n",
    "\n",
    "LONG - City Longitude - 2010 - source\n",
    "\n",
    "LAT - City Latitude - 2010 - source\n",
    "\n",
    "ALT - City Elevation (meters) - 2010 - 1 meter - source\n",
    "\n",
    "PAY_TV - PayTV users - 2019-03 - source\n",
    "\n",
    "FIXED_PHONES - Fixed Fones (not cell phones) users - 2019-03 - source\n",
    "\n",
    "AREA - City area (square kilometers) - 2018 - 1 square Kilometer (1 kilometer = 1,000,000 square meters) - source\n",
    "\n",
    "REGIAO_TUR - Turism Category Region - 2017 - source\n",
    "\n",
    "CATEGORIA_TUR - Turism Category - 2017 - source\n",
    "\n",
    "ESTIMATED_POP - Estimated Population - 2018-07 - source\n",
    "\n",
    "RURAL_URBAN - Rural or Urban Tipology - 2016 - source\n",
    "\n",
    "GVA_AGROPEC - Gross Added Value - Agropecuary - 2016 - $ 1,000 reais - source\n",
    "\n",
    "GVA_INDUSTRY - Gross Added Value - Industry - 2016 - $ 1,000 reais - source\n",
    "\n",
    "GVA_SERVICES - Gross Added Value - Services - 2016 - $ 1,000 reais - source\n",
    "\n",
    "GVA_PUBLIC - Gross Added Value - Public Services - 2016 - $ 1,000 reais - source\n",
    "\n",
    "GVA_TOTAL Total Gross Added Value - 2016 - $ 1,000 reais - source\n",
    "\n",
    "TAXES - Taxes - 2016 - $ 1,000 - reais - source\n",
    "\n",
    "GDP - Gross Domestic Product - 2016 - $ 1,000 reais - source\n",
    "\n",
    "POP_GDP - Population - 2016 - source\n",
    "\n",
    "GDP_CAPITA - Gross Domestic Product per capita - 2016 - source\n",
    "\n",
    "GVA_MAIN - Activity with higher GVA contribution - 2016 - source\n",
    "\n",
    "MUN_EXPENDIT - Municipal expenditures - in reais - 2016 - $ 1 real - source\n",
    "\n",
    "COMP_TOT - Total number of companies 2016 - source\n",
    "\n",
    "COMP_A Number of Companies: Agriculture, livestock, forestry, fishing and aquaculture - 2016 - source\n",
    "\n",
    "COMP_B Number of Companies: Extractive industries 2016 - source\n",
    "\n",
    "COMP_C Number of Companies: Industries of transformation - 2016 - source\n",
    "\n",
    "COMP_D Number of Companies: Electricity and gas - 2016 - source\n",
    "\n",
    "COMP_E Number of Companies: Water, sewage, waste management and decontamination activities - 2016 - source\n",
    "\n",
    "COMP_F Number of Companies: Construction - 2016 - source\n",
    "\n",
    "COMP_G - Number of Companies: Trade; repair of motor vehicles and motorcycles - 2016 - source\n",
    "\n",
    "COMP_H - Number of Companies: Transport, storage and mail - 2016 - source\n",
    "\n",
    "COMP_I - Number of Companies: Accommodation and food - 2016 - source\n",
    "\n",
    "COMP_J - Number of Companies: Information and communication - 2016 - source\n",
    "\n",
    "COMP_K - Number of Companies: Financial, insurance and related services activities - 2016 - source\n",
    "\n",
    "COMP_L - Number of Companies: Real estate activities - 2016 - source\n",
    "\n",
    "COMP_M - Number of Companies: Professional, scientific and technical activities - 2016 - source\n",
    "\n",
    "COMP_N - Number of Companies: Administrative activities and complementary services - 2016 - source\n",
    "\n",
    "COMP_O - Number of Companies: Public administration, defense and social security - 2016 - source\n",
    "\n",
    "COMP_P - Number of Companies: Education - 2016 - source\n",
    "\n",
    "COMP_Q - Number of Companies: Human health and social services - 2016 - source\n",
    "\n",
    "COMP_R - Number of Companies: Arts, culture, sport and recreation - 2016 - source\n",
    "\n",
    "COMP_S - Number of Companies: Other service activities - 2016 - source\n",
    "\n",
    "COMP_T - Number of Companies: Domestic services - 2016 - source\n",
    "\n",
    "COMP_U - Number of Companies: International and other extraterritorial institutions - 2016 - source\n",
    "\n",
    "HOTELS - Total number of hotels - 2019-03 - source\n",
    "\n",
    "BEDS - Total number of hotel beds - 2019-03 - source\n",
    "\n",
    "Pr_Agencies - Total number of private bank agencies - 2019-02 - source\n",
    "\n",
    "Pu_Agencies - Total number of public bank agencies - 2019-02 - source\n",
    "\n",
    "Pr_Bank - Total number of private banks - 2019-02 - source\n",
    "\n",
    "Pu_Bank - Total number of public banks 2019-02 - source\n",
    "\n",
    "Pr_Assets - Total amount of private bank assets - 2019-02 $ 1 real source\n",
    "\n",
    "Pu_Assets - Total amount of public bank assets - 2019-02 $ 1 real source\n",
    "\n",
    "Cars - Total number of cars - 2019-01 - source\n",
    "\n",
    "Motorcycles - Total number of motorcycles, scooters, moped - 2019-01 - source\n",
    "\n",
    "Wheeled_tractor - Total number of wheeled tractors - 2019-01 - source\n",
    "\n",
    "UBER - 1 if UBER 2019-05 - source\n",
    "\n",
    "MAC - Total number of Mac Donalds stores - 2018-11 - source\n",
    "\n",
    "WALLMART - Total number of Walmart Stores - 2018-12 - source\n",
    "\n",
    "POST_OFFICES - Total number of post offices - 2019-05 - source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemática\n",
    "\n",
    "A proposta desta análise é investigar um possível conjunto de variáveis para construir um modelo de regressão linear múltipla. A princípio, deseja-se modelar qual a quantidade de telefones fixos em uma cidade brasileira e quais outras variáveis possivelmente implicam em seu aumento ou decremento lineares. Essa análise seria interessante para que empresas de telefonia fixa que estejam planejando ampliar seus serviços para novas cidades brasileiras informando quais fatores mais proporcionariam um impacto direto no potencial número de usuários que alcançariam, caso se instalassem em determinada cidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possiveis variáveis\n",
    "\n",
    "Inicialmente, como ainda não sabíamos quais variáveis poderiam estar mais correlacionadas com a variável que desejamos modelar, aqui referenciada como Y (FIXED_PHONES, no dataset), realizamos uma preanálise exploratória dos dados. Para facilitar a análise em Python, declaramos uma lista com as strings que referenciam as respectivas colunas do dataset disponibilizado, que identificam as variáveis de interesse supracitadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_variables = [\n",
    "    \"TAXES\", \"IBGE_RES_POP_BRAS\", \"IBGE_RES_POP_ESTR\", \"IBGE_DU_URBAN\",\n",
    "    \"IBGE_DU_RURAL\", \"IBGE_1\", \"IBGE_1-4\", \"IBGE_5-9\", \"IBGE_10-14\", \"IBGE_15-59\",\n",
    "    \"IBGE_60+\", \"IBGE_PLANTED_AREA\", \"PAY_TV\", \"FIXED_PHONES\",\n",
    "    \"AREA\", \"ESTIMATED_POP\", \"GVA_AGROPEC\", \"GVA_INDUSTRY\", \"GVA_SERVICES\",\n",
    "    \"GVA_PUBLIC\", \"GDP\", \"POP_GDP\", \"GDP_CAPITA\", \"MUN_EXPENDIT\", \"COMP_A\",\n",
    "    \"COMP_B\", \"COMP_C\", \"COMP_D\", \"COMP_E\", \"COMP_F\", \"COMP_G\", \"COMP_H\",\n",
    "    \"COMP_I\", \"COMP_J\", \"COMP_K\", \"COMP_L\", \"COMP_M\", \"COMP_N\", \"COMP_O\",\n",
    "    \"COMP_P\", \"COMP_Q\", \"COMP_R\", \"COMP_S\", \"COMP_T\", \"COMP_U\", \"HOTELS\",\n",
    "    \"BEDS\", \"Pr_Agencies\", \"Pu_Agencies\", \"Pr_Bank\", \"Pu_Bank\", \"Pr_Assets\",\n",
    "    \"Pu_Assets\", \"Cars\", \"Motorcycles\", \"Wheeled_tractor\", \"MAC\",\n",
    "    \"POST_OFFICES\", \"WAL-MART\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E a string com a variável que queremos modelar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted = \"FIXED_PHONES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas utilizadas\n",
    "\n",
    "Para realizar a análise, como visto anteriormente, escolhemos a linguagem Python 3, visto que existem diversas bibliotecas auxiliares para fazer análise de dados. As seguintes bibliotecas foram utilizadas: **statsmodels, numpy, pandas, pprint, seaborn,** e o submódulo **pyplot** da biblioteca **matplotlib**.\n",
    "\n",
    "Para efeito de contextualização, a seguir, um breve resumo do que as principais bibliotecas utilizadas fazem:\n",
    "\n",
    "* Statsmodel é uma biblioteca de Python que provê classes e funções para a estimação de diferentes modelos estatísticos, além de conduzir testes estatísticos e exploração de dados.\n",
    "\n",
    "* Numpy é uma biblioteca para computação científica, contendo arrays n-dimensionais, funcões de algebra linear, etc. \n",
    "\n",
    "* Pandas é uma biblioteca que provê estrutura de dados e ferramentas de análise de dados fácil de usar e de alto performance para Python. \n",
    "\n",
    "* Seaborn é uma biblioteca de visualização de dados baseada no matplotlib. Provê uma interface para desenhar gráficos estatísticos atrativos e informativos.\n",
    "\n",
    "* Pyplot é uma coleção de comandos da biblioteca matplotlib, que provê a publicação de figuras em uma variedade de formatos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizando os dados\n",
    "Antes de gerar o modelo e gráficos, foi necessário isolar e converter alguns dos campos para dados numéricos, haja vista que foram codificados como strings cuja casa decimal era separada por vírgula, o que era incompatível com os módulos utilizados. Abaixo, é possível visualizar uma tabela que exibe alguns dos valores dos campos diponíveis no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brazil_cities_df = pd.read_csv('data/BRAZIL_CITIES.csv', error_bad_lines=False, sep=';', nrows=5500)\n",
    "\n",
    "brazil_cities_df['TAXES'] = brazil_cities_df['TAXES'].str.replace(',', '.').astype(float)\n",
    "for variable in all_variables:\n",
    "    if (not brazil_cities_df[variable].dtype in ['int64', 'float64']):\n",
    "        brazil_cities_df[variable].apply(lambda x: float(x.replace(',', '.')))\n",
    "\n",
    "all_variables_df = pd.DataFrame(brazil_cities_df[all_variables], columns=all_variables)\n",
    "all_variables_df = all_variables_df.fillna(0)\n",
    "# print(all_variables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de correlação\n",
    "Para visualizar a correlação entre as variáveis e ter uma ideia de quais seriam a melhor escolha pro modelo, foi utilizado o seaborn. Utilizando o heatmap, é possível verificar a intensidade da correlação para cada dupla de variáveis do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) \n",
    "sns.heatmap(all_variables_df.corr(),vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afunilamento das variaveis\n",
    "\n",
    "Como se pode ver com o gráfico acima, a cor azul indica que a maioria das variáveis estão relacionadas entre si de maneira linearmente positiva. Todavia, pelo fato de o dataset possuir muitas variáveis, fica difícil construir um modelo e visualizar as relações dos dados com todas elas. Sendo assim, a partir dos coeficientes de correlação calculados, escolhemos os dez maiores e isolamos os respectivos fatores para serem as variáveis independentes do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#top X correlações mais fortes com nossa variavel problema.\n",
    "x = 10\n",
    "correlation = all_variables_df.corr()\n",
    "correlation_problem = correlation[predicted].fillna(0).abs().sort_values(ascending=False)[1:x+1]\n",
    "print (correlation_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes do modelo a ser gerado\n",
    "\n",
    "Após a análise dos fatores com maior correlação com FIXED_PHONES, criou-se uma lista para guardar esses dez fatores selecionados do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "independent_variables = list(correlation_problem.keys())\n",
    "print('Lista com fatores mais correlacionados com FIXED_PHONES: ', independent_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de dispersão e Histograma\n",
    "\n",
    "Escohidas as melhores variáveis, construímos em seguida um plot que gera gráficos de dispersão em que podemos visualizar como cada uma das variáveis se relaciona com nossa variável Y. Como se pode ver, as variáveis escolhidas se relacionam de maneira linearmente positiva com FIXED_PHONES. Isso já era esperado, haja vista que os coeficientes apresentaram alta correlação linear (todas bem próximas de 1). Para gerar os gráficos, foi utilizado o submodulo pyplot. Para cada varíavel é mostrada o gráfico de dispersão com relação a variável Y e também um histograma da variável independente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linhas = len(independent_variables)\n",
    "index = 1\n",
    "plt.figure(figsize=(20,50))\n",
    "for i in independent_variables:\n",
    "    plt.subplot(linhas,2,index)\n",
    "    plt.scatter(all_variables_df[predicted], all_variables_df[i])\n",
    "    plt.xlabel(predicted)\n",
    "    plt.ylabel(i)\n",
    "    index += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados\n",
    "Após a organização dos dados, temos as variáveis independentes de cada elemento do dataset que iremos utilizar para gerar o modelo. É possível visualizar uma parte do dataset com as variáveis escolhidas logo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chosen_data = pd.DataFrame(all_variables_df[[predicted] + independent_variables])\n",
    "print(chosen_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados\n",
    "O dataframe é separado em uma parte para treino (gerar o modelo) e outra para testes (predição). É utilizado 80% do dataframe para treino e 20% para testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_variables = [predicted] + independent_variables\n",
    "dataframe_choosen = pd.DataFrame(all_variables_df[choosen_variables], columns=choosen_variables)\n",
    "\n",
    "# Separação em treino e teste.\n",
    "dataframe_train = dataframe_choosen.sample(frac=0.8,random_state=200)\n",
    "dataframe_test = dataframe_choosen.drop(dataframe_train.index)\n",
    "\n",
    "# Separação do Y e X\n",
    "target_train = pd.DataFrame(dataframe_train[predicted], columns = [predicted])\n",
    "predictors_train = pd.DataFrame(dataframe_train[independent_variables], columns=independent_variables)\n",
    "\n",
    "target_test = pd.DataFrame(dataframe_test[predicted],columns=[predicted])\n",
    "predictors_test = pd.DataFrame(dataframe_test[independent_variables], columns=independent_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando o modelo\n",
    "\n",
    "Após isso, isolamos os campos de interesse nas variáveis Pythonianas X e y, de modo a alimentar as funções geradoras do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fazendo um for para que a lista seja copiada sem ser por referência\n",
    "aux_ind_var = list()\n",
    "for item in independent_variables:\n",
    "    aux_ind_var.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# X são as variáveis independentes com as quais se quer modelar a dependente\n",
    "X = predictors_train[aux_ind_var]\n",
    "# y é a variável dependente que se quer prever\n",
    "y = target_train[predicted]\n",
    "\n",
    "# Construindo o modelo linear\n",
    "X2 = sm.add_constant(X)\n",
    "model = sm.OLS(y, X2).fit()\n",
    "# Criando data frame com predições\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "pprint(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando modelo inicial\n",
    "\n",
    "Ao utilizarmos todas as dez variáveis escolhidas, percebemos que, de fato, a quantidade de telefones fixos (FIXED_PHONES) sofre influência delas, pois obtivemos bons valores para R² e para a estatística F.\n",
    "\n",
    "Relembrando, as variáveis escolhidas para construir o modelo foram:\n",
    "\n",
    "* COMP_P: Number of Companies: Education - 2016\n",
    "* Pr_Agencies: Total number of private bank agencies - 2019-02\n",
    "* COMP_M: Number of Companies: Professional, scientific and technical activities - 2016\n",
    "* Cars: Number of Companies: Other service activities - 2016\n",
    "* COMP_N: Number of Companies: Administrative activities and complementary services - 2016\n",
    "* COMP_I: Number of Companies: Accommodation and food - 2016 - source\n",
    "* COMP_Q: Number of Companies: Human health and social services - 2016\n",
    "* COMP_S: Number of Companies: Other service activities - 2016\n",
    "* COMP_L: Number of Companies: Real estate activities - 2016 - source\n",
    "* MAC: Total number of Mac Donalds stores - 2018-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP_M\n",
    "\n",
    "Todavia, observando com mais atenção o p-valor para os t-tests que verificam o quanto cada fator, de fato, contribui para definir o número de telefones fixos, vemos que a variável COMP_M (número de empresas relacionadas com atividades profissionais, técnicas e científicas) apresenta um p-valor muito alto (0.733). Sendo assim, reconstruímos o modelo, retirando-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo o fator indesejado do modelo\n",
    "aux_ind_var.remove('COMP_M')\n",
    "\n",
    "# X são as variáveis independentes com as quais se quer modelar a dependente\n",
    "X = predictors_train[aux_ind_var]\n",
    "# y é a variável dependente que se quer prever\n",
    "y = target_train[predicted]\n",
    "\n",
    "# Construindo o modelo linear\n",
    "X2 = sm.add_constant(X)\n",
    "model = sm.OLS(y, X2).fit()\n",
    "# Criando data frame com predições\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "pprint(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variáveis independentes não tão independentes\n",
    "\n",
    "Outro problema constatado foi um alto valor para o condition number. O fato desse número ser muito alto, implica dizer que pode existir alta colinearidade entre os fatores utilizados ou outros problemas numéricos, como grande diferença numérica entre as unidades de cada fator. Diante disso, passamos a gerar novamente o modelo retirando as variáveis que menos contribuíam, ou cujos intervalos de confiança cruzavam o zero, que apresentavam p-valores não significativos. Para detectar quais seriam as que não possuem colinearidade entre si, utilizamos o heatmap para visualizar a correlação entre as variáveis. Após esse procedimento, chegamos a um novo modelo, agora com apenas duas variáveis independentes (COMP_L e COMP_S), mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5)) \n",
    "sns.heatmap(all_variables_df[aux_ind_var + [predicted]].corr(),vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=1000),\n",
    "square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando os fatores indesejados do modelo\n",
    "for item in ['COMP_P', 'COMP_I', 'MAC', 'COMP_N', 'Pr_Agencies', 'COMP_Q', 'Cars']:\n",
    "    if(item in aux_ind_var):\n",
    "        aux_ind_var.remove(item)\n",
    "        \n",
    "# X são as variáveis independentes com as quais se quer modelar a dependente\n",
    "X = predictors_train[aux_ind_var]\n",
    "# y é a variável dependente que se quer prever\n",
    "y = target_train[predicted]\n",
    "\n",
    "# Construindo o modelo linear\n",
    "X2 = sm.add_constant(X)\n",
    "model = sm.OLS(y, X2).fit()\n",
    "# Criando data frame com predições\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "pprint(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretando o modelo\n",
    "\n",
    "Por fim, como se pode ver na tabela gerada acima, a variável FIXED_PHONES (quantidade de telefones fixos em uma cidade brasileira), tende a crescer, linearmente, em 231.8 unidades para cada unidade acrescida de COMP_L (número de empresas imobiliárias). Analogamente, tende a crescer 89.4 unidades para cada unidade acrescida de COMP_S (número de empresas que prestam outros tipos de serviços)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando o modelo criado\n",
    "\n",
    "A seguir, algumas visualizações para facilitar a compreensão dos modelos criados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar os valores de cada FIXED_PHONES, COMP_L e COMP_S da partição de teste do dataframe.\n",
    "phones_values = target_test['FIXED_PHONES'].values\n",
    "comp_s_values = predictors_test['COMP_S'].values\n",
    "comp_l_values = predictors_test['COMP_L'].values\n",
    "\n",
    "# Cálculo de regressão linear com os valores dados pelo modelo.\n",
    "predicted_phones =[]\n",
    "for i in range(len(comp_s_values)):\n",
    "    predicted_phones.append((comp_s_values[i]*84.8383) + (comp_l_values[i]*239.8007))\n",
    "    \n",
    "lista = [i for i in range(len(phones_values))]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(lista, predicted_phones, 'o', color='red', label=\"Predicted\")\n",
    "plt.plot(lista, phones_values, '', label=\"True\")\n",
    "plt.legend(loc=\"best\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o gráfico acima, é possível perceber que os dados preditos com o modelo da regressão linear múltipla se aproximam bastante dos valores reais, indicando que é um bom modelo que pode ser usado para prever a variável Y caso tenhamos as variáveis X.\n",
    "Em vermelho há os valores de Y produzidos pelo modelo, dado os valores das variáveis X. Em azul há os valores reais de Y da base de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
